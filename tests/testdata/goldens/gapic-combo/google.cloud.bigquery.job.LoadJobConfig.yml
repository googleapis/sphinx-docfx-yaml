### YamlMime:UniversalReference
api_name: []
items:
- attributes: []
  children:
  - google.cloud.bigquery.job.LoadJobConfig.__setattr__
  - google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows
  - google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines
  - google.cloud.bigquery.job.LoadJobConfig.autodetect
  - google.cloud.bigquery.job.LoadJobConfig.clustering_fields
  - google.cloud.bigquery.job.LoadJobConfig.create_disposition
  - google.cloud.bigquery.job.LoadJobConfig.decimal_target_types
  - google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration
  - google.cloud.bigquery.job.LoadJobConfig.destination_table_description
  - google.cloud.bigquery.job.LoadJobConfig.destination_table_friendly_name
  - google.cloud.bigquery.job.LoadJobConfig.encoding
  - google.cloud.bigquery.job.LoadJobConfig.field_delimiter
  - google.cloud.bigquery.job.LoadJobConfig.from_api_repr
  - google.cloud.bigquery.job.LoadJobConfig.hive_partitioning
  - google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values
  - google.cloud.bigquery.job.LoadJobConfig.labels
  - google.cloud.bigquery.job.LoadJobConfig.max_bad_records
  - google.cloud.bigquery.job.LoadJobConfig.null_marker
  - google.cloud.bigquery.job.LoadJobConfig.parquet_options
  - google.cloud.bigquery.job.LoadJobConfig.projection_fields
  - google.cloud.bigquery.job.LoadJobConfig.quote_character
  - google.cloud.bigquery.job.LoadJobConfig.range_partitioning
  - google.cloud.bigquery.job.LoadJobConfig.schema
  - google.cloud.bigquery.job.LoadJobConfig.schema_update_options
  - google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows
  - google.cloud.bigquery.job.LoadJobConfig.source_format
  - google.cloud.bigquery.job.LoadJobConfig.time_partitioning
  - google.cloud.bigquery.job.LoadJobConfig.to_api_repr
  - google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types
  - google.cloud.bigquery.job.LoadJobConfig.write_disposition
  - google.cloud.bigquery.job.LoadJobConfig.__init__
  - google.cloud.bigquery.job.LoadJobConfig
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig
  inheritance:
  - inheritance:
    - type: builtins.object
    type: google.cloud.bigquery.job.base._JobConfig
  langs:
  - python
  module: google.cloud.bigquery.job
  name: LoadJobConfig
  source:
    id: LoadJobConfig
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 33
  summary: 'Configuration options for load jobs.


    Set properties on the constructed configuration by using the property name

    as the name of a keyword argument. Values which are unset or :data:`None`

    use the BigQuery REST API default values. See the `BigQuery REST API

    reference documentation

    <https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad>`_

    for a list of default values.


    Required options differ based on the

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.source_format">source_format</xref>
    value.

    For example, the BigQuery API''s default value for

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.source_format">source_format</xref>
    is `"CSV"`.

    When loading a CSV file, either

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.schema">schema</xref> must
    be set or

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.autodetect">autodetect</xref>
    must be set to

    :data:`True`.


    '
  syntax:
    content: LoadJobConfig(**kwargs)
    parameters: []
  type: class
  uid: google.cloud.bigquery.job.LoadJobConfig
- attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.__setattr__
  langs:
  - python
  module: google.cloud.bigquery.job
  name: __setattr__
  source:
    id: __setattr__
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 767
  summary: 'Override to be able to raise error if an unknown property is being set


    '
  syntax:
    content: __setattr__(name, value)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.LoadJobConfig.__setattr__
- &id001
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows
  langs:
  - python
  module: google.cloud.bigquery.job
  name: allow_jagged_rows
  source:
    id: allow_jagged_rows
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[bool]: Allow missing trailing optional columns (CSV only).


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.allow_jagged_rows


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows
- *id001
- &id002
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines
  langs:
  - python
  module: google.cloud.bigquery.job
  name: allow_quoted_newlines
  source:
    id: allow_quoted_newlines
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[bool]: Allow quoted data containing newline characters (CSV only).


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.allow_quoted_newlines


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines
- *id002
- &id003
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.autodetect
  langs:
  - python
  module: google.cloud.bigquery.job
  name: autodetect
  source:
    id: autodetect
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[bool]: Automatically infer the schema from a sample of the data.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.autodetect


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.autodetect
- *id003
- &id004
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.clustering_fields
  langs:
  - python
  module: google.cloud.bigquery.job
  name: clustering_fields
  source:
    id: clustering_fields
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[List[str]]: Fields defining clustering for the table


    (Defaults to :data:`None`).


    Clustering fields are immutable after table creation.


    <aside class="note">

    <b>Note:</b>

    BigQuery supports clustering for both partitioned and

    non-partitioned tables.


    </aside>'
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.clustering_fields
- *id004
- &id005
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.create_disposition
  langs:
  - python
  module: google.cloud.bigquery.job
  name: create_disposition
  source:
    id: create_disposition
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.job.CreateDisposition">google.cloud.bigquery.job.CreateDisposition</xref>]:
    Specifies behavior

    for creating tables.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.create_disposition


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.create_disposition
- *id005
- &id006
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.decimal_target_types
  langs:
  - python
  module: google.cloud.bigquery.job
  name: decimal_target_types
  source:
    id: decimal_target_types
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Possible SQL data types to which the source decimal values are converted.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.decimal_target_types


    .. versionadded:: 2.21.0


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.decimal_target_types
- *id006
- &id007
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration
  langs:
  - python
  module: google.cloud.bigquery.job
  name: destination_encryption_configuration
  source:
    id: destination_encryption_configuration
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.encryption_configuration.EncryptionConfiguration">google.cloud.bigquery.encryption_configuration.EncryptionConfiguration</xref>]:
    Custom

    encryption configuration for the destination table.


    Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`

    if using default encryption.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.destination_encryption_configuration


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration
- *id007
- &id008
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.destination_table_description
  langs:
  - python
  module: google.cloud.bigquery.job
  name: destination_table_description
  source:
    id: destination_table_description
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Description of the destination table.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.description


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_table_description
- *id008
- &id009
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.destination_table_friendly_name
  langs:
  - python
  module: google.cloud.bigquery.job
  name: destination_table_friendly_name
  source:
    id: destination_table_friendly_name
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Name given to destination table.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.friendly_name


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_table_friendly_name
- *id009
- &id010
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.encoding
  langs:
  - python
  module: google.cloud.bigquery.job
  name: encoding
  source:
    id: encoding
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.job.Encoding">google.cloud.bigquery.job.Encoding</xref>]:
    The character encoding of the

    data.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.encoding


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.encoding
- *id010
- &id011
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.field_delimiter
  langs:
  - python
  module: google.cloud.bigquery.job
  name: field_delimiter
  source:
    id: field_delimiter
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: The separator for fields in a CSV file.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.field_delimiter


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.field_delimiter
- *id011
- attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.from_api_repr
  langs:
  - python
  module: google.cloud.bigquery.job
  name: from_api_repr
  source:
    id: from_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 910
  summary: 'Factory: construct a job configuration given its API representation

    '
  syntax:
    content: 'from_api_repr(resource: dict)'
    parameters:
    - description: A job configuration in the same representation as is returned from
        the API.
      id: resource
      var_type: Dict
    returns:
    - description: Configuration parsed from <code>resource</code>.
      var_type: google.cloud.bigquery.job._JobConfig
  type: method
  uid: google.cloud.bigquery.job.LoadJobConfig.from_api_repr
- &id012
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.hive_partitioning
  langs:
  - python
  module: google.cloud.bigquery.job
  name: hive_partitioning
  source:
    id: hive_partitioning
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[`.external_config.HivePartitioningOptions`]: [Beta] When set,         it
    configures hive partitioning support.


    <aside class="note">

    <b>Note:</b>

    **Experimental**. This feature is experimental and might change or

    have limited support.

    </aside>

    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.hive_partitioning_options


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.hive_partitioning
- *id012
- &id013
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values
  langs:
  - python
  module: google.cloud.bigquery.job
  name: ignore_unknown_values
  source:
    id: ignore_unknown_values
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[bool]: Ignore extra values not represented in the table schema.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.ignore_unknown_values


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values
- *id013
- &id014
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.labels
  langs:
  - python
  module: google.cloud.bigquery.job
  name: labels
  source:
    id: labels
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Dict[str, str]: Labels for the job.


    This method always returns a dict. Once a job has been created on the

    server, its labels cannot be modified anymore.

    '
  syntax:
    exceptions:
    - description: If <code>value</code> type is invalid.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.labels
- *id014
- &id015
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.max_bad_records
  langs:
  - python
  module: google.cloud.bigquery.job
  name: max_bad_records
  source:
    id: max_bad_records
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[int]: Number of invalid rows to ignore.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.max_bad_records


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.max_bad_records
- *id015
- &id016
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.null_marker
  langs:
  - python
  module: google.cloud.bigquery.job
  name: null_marker
  source:
    id: null_marker
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Represents a null value (CSV only).


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.null_marker


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.null_marker
- *id016
- &id017
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.parquet_options
  langs:
  - python
  module: google.cloud.bigquery.job
  name: parquet_options
  source:
    id: parquet_options
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: "Optional[<xref uid=\"google.cloud.bigquery.format_options.ParquetOptions\"\
    >google.cloud.bigquery.format_options.ParquetOptions</xref>]: Additional\n   \
    \ properties to set if `sourceFormat` is set to PARQUET.\n\nSee:\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.parquet_options\n\
    \n"
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.parquet_options
- *id017
- &id018
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.projection_fields
  langs:
  - python
  module: google.cloud.bigquery.job
  name: projection_fields
  source:
    id: projection_fields
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[List[str]]: If

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.source_format">source_format</xref>
    is set to

    "DATASTORE_BACKUP", indicates which entity properties to load into

    BigQuery from a Cloud Datastore backup.


    Property names are case sensitive and must be top-level properties. If

    no properties are specified, BigQuery loads all properties. If any

    named property isn''t found in the Cloud Datastore backup, an invalid

    error is returned in the job result.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.projection_fields


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.projection_fields
- *id018
- &id019
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.quote_character
  langs:
  - python
  module: google.cloud.bigquery.job
  name: quote_character
  source:
    id: quote_character
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Character used to quote data sections (CSV only).


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.quote


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.quote_character
- *id019
- &id020
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.range_partitioning
  langs:
  - python
  module: google.cloud.bigquery.job
  name: range_partitioning
  source:
    id: range_partitioning
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.table.RangePartitioning">google.cloud.bigquery.table.RangePartitioning</xref>]:

    Configures range-based partitioning for destination table.


    <aside class="note">

    <b>Note:</b>

    **Beta**. The integer range partitioning feature is in a

    pre-release state and might change or have limited support.

    </aside>

    Only specify at most one of

    xref_time_partitioning or

    xref_range_partitioning.

    '
  syntax:
    exceptions:
    - description: If the value is not <xref uid="google.cloud.bigquery.table.RangePartitioning">RangePartitioning</xref>
        or :data:<code>None</code>.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.range_partitioning
- *id020
- &id021
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.schema
  langs:
  - python
  module: google.cloud.bigquery.job
  name: schema
  source:
    id: schema
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[Sequence[Union[             <xref uid="google.cloud.bigquery.schema.SchemaField">SchemaField</xref>,             Mapping[str,
    Any]         ]]]: Schema of the destination table.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.schema


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.schema
- *id021
- &id022
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.schema_update_options
  langs:
  - python
  module: google.cloud.bigquery.job
  name: schema_update_options
  source:
    id: schema_update_options
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[List[<xref uid="google.cloud.bigquery.job.SchemaUpdateOption">google.cloud.bigquery.job.SchemaUpdateOption</xref>]]:
    Specifies

    updates to the destination table schema to allow as a side effect of

    the load job.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.schema_update_options
- *id022
- &id023
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows
  langs:
  - python
  module: google.cloud.bigquery.job
  name: skip_leading_rows
  source:
    id: skip_leading_rows
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[int]: Number of rows to skip when reading data (CSV only).


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.skip_leading_rows


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows
- *id023
- &id024
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.source_format
  langs:
  - python
  module: google.cloud.bigquery.job
  name: source_format
  source:
    id: source_format
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.job.SourceFormat">google.cloud.bigquery.job.SourceFormat</xref>]:
    File format of the data.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.source_format


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.source_format
- *id024
- &id025
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.time_partitioning
  langs:
  - python
  module: google.cloud.bigquery.job
  name: time_partitioning
  source:
    id: time_partitioning
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.table.TimePartitioning">google.cloud.bigquery.table.TimePartitioning</xref>]:
    Specifies time-based

    partitioning for the destination table.


    Only specify at most one of

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.time_partitioning">time_partitioning</xref>
    or

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.range_partitioning">range_partitioning</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.time_partitioning
- *id025
- attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.to_api_repr
  langs:
  - python
  module: google.cloud.bigquery.job
  name: to_api_repr
  source:
    id: to_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 865
  summary: 'Build an API representation of the job config.

    '
  syntax:
    content: to_api_repr()
    parameters: []
    returns:
    - description: A dictionary in the format used by the BigQuery API.
      var_type: Dict
  type: method
  uid: google.cloud.bigquery.job.LoadJobConfig.to_api_repr
- &id026
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types
  langs:
  - python
  module: google.cloud.bigquery.job
  name: use_avro_logical_types
  source:
    id: use_avro_logical_types
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[bool]: For loads of Avro data, governs whether Avro logical types
    are

    converted to their corresponding BigQuery types (e.g. TIMESTAMP) rather than

    raw types (e.g. INTEGER).


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types
- *id026
- &id027
  attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.write_disposition
  langs:
  - python
  module: google.cloud.bigquery.job
  name: write_disposition
  source:
    id: write_disposition
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[<xref uid="google.cloud.bigquery.job.WriteDisposition">google.cloud.bigquery.job.WriteDisposition</xref>]:
    Action that occurs if

    the destination table already exists.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.write_disposition


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.LoadJobConfig.write_disposition
- *id027
- attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig.__init__
  langs:
  - python
  module: google.cloud.bigquery.job
  name: __init__
  source:
    id: __init__
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 53
  summary: 'Initialize self.  See help(type(self)) for accurate signature.


    '
  syntax:
    content: __init__(**kwargs)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.LoadJobConfig.__init__
- attributes: []
  class: google.cloud.bigquery.job.LoadJobConfig
  fullName: google.cloud.bigquery.job.LoadJobConfig
  inheritance:
  - inheritance:
    - type: builtins.object
    type: google.cloud.bigquery.job.base._JobConfig
  langs:
  - python
  module: google.cloud.bigquery.job
  name: LoadJobConfig
  source:
    id: LoadJobConfig
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/load.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 33
  summary: 'Configuration options for load jobs.


    Set properties on the constructed configuration by using the property name

    as the name of a keyword argument. Values which are unset or :data:`None`

    use the BigQuery REST API default values. See the `BigQuery REST API

    reference documentation

    <https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad>`_

    for a list of default values.


    Required options differ based on the

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.source_format">source_format</xref>
    value.

    For example, the BigQuery API''s default value for

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.source_format">source_format</xref>
    is `"CSV"`.

    When loading a CSV file, either

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.schema">schema</xref> must
    be set or

    <xref uid="google.cloud.bigquery.job.LoadJobConfig.autodetect">autodetect</xref>
    must be set to

    :data:`True`.


    '
  syntax:
    content: LoadJobConfig(**kwargs)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.LoadJobConfig
references:
- fullName: google.cloud.bigquery.job.LoadJobConfig.__setattr__
  isExternal: false
  name: __setattr__
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.__setattr__
- fullName: google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows
  isExternal: false
  name: allow_jagged_rows
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows
- fullName: google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines
  isExternal: false
  name: allow_quoted_newlines
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines
- fullName: google.cloud.bigquery.job.LoadJobConfig.autodetect
  isExternal: false
  name: autodetect
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.autodetect
- fullName: google.cloud.bigquery.job.LoadJobConfig.clustering_fields
  isExternal: false
  name: clustering_fields
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.clustering_fields
- fullName: google.cloud.bigquery.job.LoadJobConfig.create_disposition
  isExternal: false
  name: create_disposition
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.create_disposition
- fullName: google.cloud.bigquery.job.LoadJobConfig.decimal_target_types
  isExternal: false
  name: decimal_target_types
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.decimal_target_types
- fullName: google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration
  isExternal: false
  name: destination_encryption_configuration
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration
- fullName: google.cloud.bigquery.job.LoadJobConfig.destination_table_description
  isExternal: false
  name: destination_table_description
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_table_description
- fullName: google.cloud.bigquery.job.LoadJobConfig.destination_table_friendly_name
  isExternal: false
  name: destination_table_friendly_name
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.destination_table_friendly_name
- fullName: google.cloud.bigquery.job.LoadJobConfig.encoding
  isExternal: false
  name: encoding
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.encoding
- fullName: google.cloud.bigquery.job.LoadJobConfig.field_delimiter
  isExternal: false
  name: field_delimiter
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.field_delimiter
- fullName: google.cloud.bigquery.job.LoadJobConfig.from_api_repr
  isExternal: false
  name: from_api_repr
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.from_api_repr
- fullName: google.cloud.bigquery.job.LoadJobConfig.hive_partitioning
  isExternal: false
  name: hive_partitioning
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.hive_partitioning
- fullName: google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values
  isExternal: false
  name: ignore_unknown_values
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values
- fullName: google.cloud.bigquery.job.LoadJobConfig.labels
  isExternal: false
  name: labels
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.labels
- fullName: google.cloud.bigquery.job.LoadJobConfig.max_bad_records
  isExternal: false
  name: max_bad_records
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.max_bad_records
- fullName: google.cloud.bigquery.job.LoadJobConfig.null_marker
  isExternal: false
  name: null_marker
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.null_marker
- fullName: google.cloud.bigquery.job.LoadJobConfig.parquet_options
  isExternal: false
  name: parquet_options
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.parquet_options
- fullName: google.cloud.bigquery.job.LoadJobConfig.projection_fields
  isExternal: false
  name: projection_fields
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.projection_fields
- fullName: google.cloud.bigquery.job.LoadJobConfig.quote_character
  isExternal: false
  name: quote_character
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.quote_character
- fullName: google.cloud.bigquery.job.LoadJobConfig.range_partitioning
  isExternal: false
  name: range_partitioning
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.range_partitioning
- fullName: google.cloud.bigquery.job.LoadJobConfig.schema
  isExternal: false
  name: schema
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.schema
- fullName: google.cloud.bigquery.job.LoadJobConfig.schema_update_options
  isExternal: false
  name: schema_update_options
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.schema_update_options
- fullName: google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows
  isExternal: false
  name: skip_leading_rows
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows
- fullName: google.cloud.bigquery.job.LoadJobConfig.source_format
  isExternal: false
  name: source_format
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.source_format
- fullName: google.cloud.bigquery.job.LoadJobConfig.time_partitioning
  isExternal: false
  name: time_partitioning
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.time_partitioning
- fullName: google.cloud.bigquery.job.LoadJobConfig.to_api_repr
  isExternal: false
  name: to_api_repr
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.to_api_repr
- fullName: google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types
  isExternal: false
  name: use_avro_logical_types
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types
- fullName: google.cloud.bigquery.job.LoadJobConfig.write_disposition
  isExternal: false
  name: write_disposition
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.write_disposition
- fullName: google.cloud.bigquery.job.LoadJobConfig.__init__
  isExternal: false
  name: __init__
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig.__init__
- fullName: google.cloud.bigquery.job.LoadJobConfig
  isExternal: false
  name: LoadJobConfig
  parent: google.cloud.bigquery.job.LoadJobConfig
  uid: google.cloud.bigquery.job.LoadJobConfig
