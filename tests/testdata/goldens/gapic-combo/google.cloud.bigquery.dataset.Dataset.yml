### YamlMime:UniversalReference
api_name: []
items:
- attributes: []
  children:
  - google.cloud.bigquery.dataset.Dataset.access_entries
  - google.cloud.bigquery.dataset.Dataset.created
  - google.cloud.bigquery.dataset.Dataset.dataset_id
  - google.cloud.bigquery.dataset.Dataset.default_encryption_configuration
  - google.cloud.bigquery.dataset.Dataset.default_partition_expiration_ms
  - google.cloud.bigquery.dataset.Dataset.default_table_expiration_ms
  - google.cloud.bigquery.dataset.Dataset.description
  - google.cloud.bigquery.dataset.Dataset.etag
  - google.cloud.bigquery.dataset.Dataset.friendly_name
  - google.cloud.bigquery.dataset.Dataset.from_api_repr
  - google.cloud.bigquery.dataset.Dataset.from_string
  - google.cloud.bigquery.dataset.Dataset.full_dataset_id
  - google.cloud.bigquery.dataset.Dataset.labels
  - google.cloud.bigquery.dataset.Dataset.location
  - google.cloud.bigquery.dataset.Dataset.model
  - google.cloud.bigquery.dataset.Dataset.modified
  - google.cloud.bigquery.dataset.Dataset.path
  - google.cloud.bigquery.dataset.Dataset.project
  - google.cloud.bigquery.dataset.Dataset.reference
  - google.cloud.bigquery.dataset.Dataset.routine
  - google.cloud.bigquery.dataset.Dataset.self_link
  - google.cloud.bigquery.dataset.Dataset.table
  - google.cloud.bigquery.dataset.Dataset.to_api_repr
  - google.cloud.bigquery.dataset.Dataset.__init__
  - google.cloud.bigquery.dataset.Dataset
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: Dataset
  source:
    id: Dataset
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 507
  summary: 'Datasets are containers for tables.


    See

    https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource-dataset

    '
  syntax:
    content: Dataset(dataset_ref)
    parameters:
    - description: A pointer to a dataset. If <code>dataset_ref</code> is a string,
        it must include both the project ID and the dataset ID, separated by <code>.</code>.
      id: dataset_ref
      var_type: Union[<xref uid="google.cloud.bigquery.dataset.DatasetReference">google.cloud.bigquery.dataset.DatasetReference</xref>,
        str]
  type: class
  uid: google.cloud.bigquery.dataset.Dataset
- &id001
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.access_entries
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: access_entries
  source:
    id: access_entries
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'List[<xref uid="google.cloud.bigquery.dataset.AccessEntry">google.cloud.bigquery.dataset.AccessEntry</xref>]:
    Dataset''s access

    entries.


    `role` augments the entity type and must be present **unless** the

    entity type is `view` or `routine`.

    '
  syntax:
    exceptions:
    - description: If 'value' is not a sequence
      var_type: TypeError
    - description: If any item in the sequence is not an <xref uid="google.cloud.bigquery.dataset.AccessEntry">AccessEntry</xref>.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.access_entries
- *id001
- &id002
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.created
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: created
  source:
    id: created
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[datetime.datetime, None]: Datetime at which the dataset was

    created (:data:`None` until set from the server).


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.created
- *id002
- &id003
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.dataset_id
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: dataset_id
  source:
    id: dataset_id
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: Dataset ID.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.dataset_id
- *id003
- &id004
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.default_encryption_configuration
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: default_encryption_configuration
  source:
    id: default_encryption_configuration
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: '<xref uid="google.cloud.bigquery.encryption_configuration.EncryptionConfiguration">google.cloud.bigquery.encryption_configuration.EncryptionConfiguration</xref>:
    Custom

    encryption configuration for all tables in the dataset.


    Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`

    if using default encryption.


    See `protecting data with Cloud KMS keys

    <https://cloud.google.com/bigquery/docs/customer-managed-encryption>`_

    in the BigQuery documentation.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.default_encryption_configuration
- *id004
- &id005
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.default_partition_expiration_ms
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: default_partition_expiration_ms
  source:
    id: default_partition_expiration_ms
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[int]: The default partition expiration for all

    partitioned tables in the dataset, in milliseconds.


    Once this property is set, all newly-created partitioned tables in

    the dataset will have an `time_paritioning.expiration_ms` property

    set to this value, and changing the value will only affect new

    tables, not existing ones. The storage in a partition will have an

    expiration time of its partition time plus this value.


    Setting this property overrides the use of

    `default_table_expiration_ms` for partitioned tables: only one of

    `default_table_expiration_ms` and

    `default_partition_expiration_ms` will be used for any new

    partitioned table. If you provide an explicit

    `time_partitioning.expiration_ms` when creating or updating a

    partitioned table, that value takes precedence over the default

    partition expiration time indicated by this property.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.default_partition_expiration_ms
- *id005
- &id006
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.default_table_expiration_ms
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: default_table_expiration_ms
  source:
    id: default_table_expiration_ms
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[int, None]: Default expiration time for tables in the dataset

    (defaults to :data:`None`).

    '
  syntax:
    exceptions:
    - description: For invalid value types.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.default_table_expiration_ms
- *id006
- &id007
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.description
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: description
  source:
    id: description
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Description of the dataset as set by the user

    (defaults to :data:`None`).

    '
  syntax:
    exceptions:
    - description: for invalid value types.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.description
- *id007
- &id008
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.etag
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: etag
  source:
    id: etag
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[str, None]: ETag for the dataset resource (:data:`None` until

    set from the server).


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.etag
- *id008
- &id009
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.friendly_name
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: friendly_name
  source:
    id: friendly_name
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[str, None]: Title of the dataset as set by the user

    (defaults to :data:`None`).

    '
  syntax:
    exceptions:
    - description: for invalid value types.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.friendly_name
- *id009
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.from_api_repr
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: from_api_repr
  source:
    id: from_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 787
  summary: 'Factory: construct a dataset given its API representation

    '
  syntax:
    content: 'from_api_repr(resource: dict)'
    parameters: []
    returns:
    - description: Dataset parsed from <code>resource</code>.
      var_type: google.cloud.bigquery.dataset.Dataset
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.from_api_repr
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.from_string
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: from_string
  source:
    id: from_string
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 763
  summary: 'Construct a dataset from fully-qualified dataset ID.

    '
  syntax:
    content: 'from_string(full_dataset_id: str)'
    exceptions:
    - description: If <code>full_dataset_id</code> is not a fully-qualified dataset
        ID in standard SQL format.
      var_type: ValueError
    parameters:
    - description: A fully-qualified dataset ID in standard SQL format. Must include
        both the project ID and the dataset ID, separated by <code>.</code>.
      id: full_dataset_id
      var_type: str
    returns:
    - description: Dataset parsed from <code>full_dataset_id</code>.
      var_type: 'Dataset .. rubric:: Examples >>> Dataset.from_string(''my-project-id.some_dataset'')
        Dataset(DatasetReference(''my-project-id'', ''some_dataset''))'
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.from_string
- &id010
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.full_dataset_id
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: full_dataset_id
  source:
    id: full_dataset_id
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[str, None]: ID for the dataset resource (:data:`None` until

    set from the server)


    In the format `project_id:dataset_id`.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.full_dataset_id
- *id010
- &id011
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.labels
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: labels
  source:
    id: labels
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Dict[str, str]: Labels for the dataset.


    This method always returns a dict. To change a dataset''s labels,

    modify the dict, then call

    xref_update_dataset. To delete

    a label, set its value to :data:`None` before updating.

    '
  syntax:
    exceptions:
    - description: for invalid value types.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.labels
- *id011
- &id012
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.location
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: location
  source:
    id: location
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[str, None]: Location in which the dataset is hosted as set by

    the user (defaults to :data:`None`).

    '
  syntax:
    exceptions:
    - description: for invalid value types.
      var_type: ValueError
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.location
- *id012
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.model
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: model
  source:
    id: model
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 47
  summary: 'Constructs a ModelReference.

    '
  syntax:
    content: model(model_id)
    parameters:
    - description: the ID of the model.
      id: model_id
      var_type: str
    returns:
    - description: A ModelReference for a model in this dataset.
      var_type: <xref uid="google.cloud.bigquery.model.ModelReference">google.cloud.bigquery.model.ModelReference</xref>
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.model
- &id013
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.modified
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: modified
  source:
    id: modified
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[datetime.datetime, None]: Datetime at which the dataset was

    last modified (:data:`None` until set from the server).


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.modified
- *id013
- &id014
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.path
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: path
  source:
    id: path
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: URL path for the dataset based on project and dataset ID.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.path
- *id014
- &id015
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.project
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: project
  source:
    id: project
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: Project ID of the project bound to the dataset.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.project
- *id015
- &id016
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.reference
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: reference
  source:
    id: reference
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: '<xref uid="google.cloud.bigquery.dataset.DatasetReference">google.cloud.bigquery.dataset.DatasetReference</xref>:
    A reference to this

    dataset.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.reference
- *id016
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.routine
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: routine
  source:
    id: routine
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 62
  summary: 'Constructs a RoutineReference.

    '
  syntax:
    content: routine(routine_id)
    parameters:
    - description: the ID of the routine.
      id: routine_id
      var_type: str
    returns:
    - description: A RoutineReference for a routine in this dataset.
      var_type: <xref uid="google.cloud.bigquery.routine.RoutineReference">google.cloud.bigquery.routine.RoutineReference</xref>
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.routine
- &id017
  attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.self_link
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: self_link
  source:
    id: self_link
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[str, None]: URL for the dataset resource (:data:`None` until

    set from the server).


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.dataset.Dataset.self_link
- *id017
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.table
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: table
  source:
    id: table
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 34
  summary: 'Constructs a TableReference.

    '
  syntax:
    content: 'table(table_id: str)'
    parameters:
    - description: The ID of the table.
      id: table_id
      var_type: str
    returns:
    - description: A table reference for a table in this dataset.
      var_type: <xref uid="google.cloud.bigquery.table.TableReference">google.cloud.bigquery.table.TableReference</xref>
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.table
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.to_api_repr
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: to_api_repr
  source:
    id: to_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 813
  summary: 'Construct the API resource representation of this dataset

    '
  syntax:
    content: to_api_repr()
    parameters: []
    returns:
    - description: The dataset represented as an API resource
      var_type: Dict[str, object]
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.to_api_repr
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset.__init__
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: __init__
  source:
    id: __init__
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 529
  summary: 'Initialize self.  See help(type(self)) for accurate signature.


    '
  syntax:
    content: __init__(dataset_ref)
    parameters: []
  type: method
  uid: google.cloud.bigquery.dataset.Dataset.__init__
- attributes: []
  class: google.cloud.bigquery.dataset.Dataset
  fullName: google.cloud.bigquery.dataset.Dataset
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: google.cloud.bigquery.dataset
  name: Dataset
  source:
    id: Dataset
    path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/dataset.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 507
  summary: 'Datasets are containers for tables.


    See

    https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource-dataset

    '
  syntax:
    content: Dataset(dataset_ref)
    parameters:
    - description: A pointer to a dataset. If <code>dataset_ref</code> is a string,
        it must include both the project ID and the dataset ID, separated by <code>.</code>.
      id: dataset_ref
      var_type: Union[<xref uid="google.cloud.bigquery.dataset.DatasetReference">google.cloud.bigquery.dataset.DatasetReference</xref>,
        str]
  type: method
  uid: google.cloud.bigquery.dataset.Dataset
references:
- fullName: google.cloud.bigquery.dataset.Dataset.access_entries
  isExternal: false
  name: access_entries
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.access_entries
- fullName: google.cloud.bigquery.dataset.Dataset.created
  isExternal: false
  name: created
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.created
- fullName: google.cloud.bigquery.dataset.Dataset.dataset_id
  isExternal: false
  name: dataset_id
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.dataset_id
- fullName: google.cloud.bigquery.dataset.Dataset.default_encryption_configuration
  isExternal: false
  name: default_encryption_configuration
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.default_encryption_configuration
- fullName: google.cloud.bigquery.dataset.Dataset.default_partition_expiration_ms
  isExternal: false
  name: default_partition_expiration_ms
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.default_partition_expiration_ms
- fullName: google.cloud.bigquery.dataset.Dataset.default_table_expiration_ms
  isExternal: false
  name: default_table_expiration_ms
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.default_table_expiration_ms
- fullName: google.cloud.bigquery.dataset.Dataset.description
  isExternal: false
  name: description
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.description
- fullName: google.cloud.bigquery.dataset.Dataset.etag
  isExternal: false
  name: etag
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.etag
- fullName: google.cloud.bigquery.dataset.Dataset.friendly_name
  isExternal: false
  name: friendly_name
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.friendly_name
- fullName: google.cloud.bigquery.dataset.Dataset.from_api_repr
  isExternal: false
  name: from_api_repr
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.from_api_repr
- fullName: google.cloud.bigquery.dataset.Dataset.from_string
  isExternal: false
  name: from_string
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.from_string
- fullName: google.cloud.bigquery.dataset.Dataset.full_dataset_id
  isExternal: false
  name: full_dataset_id
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.full_dataset_id
- fullName: google.cloud.bigquery.dataset.Dataset.labels
  isExternal: false
  name: labels
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.labels
- fullName: google.cloud.bigquery.dataset.Dataset.location
  isExternal: false
  name: location
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.location
- fullName: google.cloud.bigquery.dataset.Dataset.model
  isExternal: false
  name: model
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.model
- fullName: google.cloud.bigquery.dataset.Dataset.modified
  isExternal: false
  name: modified
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.modified
- fullName: google.cloud.bigquery.dataset.Dataset.path
  isExternal: false
  name: path
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.path
- fullName: google.cloud.bigquery.dataset.Dataset.project
  isExternal: false
  name: project
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.project
- fullName: google.cloud.bigquery.dataset.Dataset.reference
  isExternal: false
  name: reference
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.reference
- fullName: google.cloud.bigquery.dataset.Dataset.routine
  isExternal: false
  name: routine
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.routine
- fullName: google.cloud.bigquery.dataset.Dataset.self_link
  isExternal: false
  name: self_link
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.self_link
- fullName: google.cloud.bigquery.dataset.Dataset.table
  isExternal: false
  name: table
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.table
- fullName: google.cloud.bigquery.dataset.Dataset.to_api_repr
  isExternal: false
  name: to_api_repr
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.to_api_repr
- fullName: google.cloud.bigquery.dataset.Dataset.__init__
  isExternal: false
  name: __init__
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset.__init__
- fullName: google.cloud.bigquery.dataset.Dataset
  isExternal: false
  name: Dataset
  parent: google.cloud.bigquery.dataset.Dataset
  uid: google.cloud.bigquery.dataset.Dataset
