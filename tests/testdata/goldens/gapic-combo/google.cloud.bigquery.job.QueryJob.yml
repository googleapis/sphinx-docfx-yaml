### YamlMime:UniversalReference
api_name: []
items:
- attributes: []
  children:
  - google.cloud.bigquery.job.QueryJob.add_done_callback
  - google.cloud.bigquery.job.QueryJob.allow_large_results
  - google.cloud.bigquery.job.QueryJob.billing_tier
  - google.cloud.bigquery.job.QueryJob.cache_hit
  - google.cloud.bigquery.job.QueryJob.cancel
  - google.cloud.bigquery.job.QueryJob.cancelled
  - google.cloud.bigquery.job.QueryJob.clustering_fields
  - google.cloud.bigquery.job.QueryJob.connection_properties
  - google.cloud.bigquery.job.QueryJob.create_disposition
  - google.cloud.bigquery.job.QueryJob.create_session
  - google.cloud.bigquery.job.QueryJob.created
  - google.cloud.bigquery.job.QueryJob.ddl_operation_performed
  - google.cloud.bigquery.job.QueryJob.ddl_target_routine
  - google.cloud.bigquery.job.QueryJob.ddl_target_table
  - google.cloud.bigquery.job.QueryJob.default_dataset
  - google.cloud.bigquery.job.QueryJob.destination
  - google.cloud.bigquery.job.QueryJob.destination_encryption_configuration
  - google.cloud.bigquery.job.QueryJob.done
  - google.cloud.bigquery.job.QueryJob.dry_run
  - google.cloud.bigquery.job.QueryJob.ended
  - google.cloud.bigquery.job.QueryJob.error_result
  - google.cloud.bigquery.job.QueryJob.errors
  - google.cloud.bigquery.job.QueryJob.estimated_bytes_processed
  - google.cloud.bigquery.job.QueryJob.etag
  - google.cloud.bigquery.job.QueryJob.exception
  - google.cloud.bigquery.job.QueryJob.exists
  - google.cloud.bigquery.job.QueryJob.flatten_results
  - google.cloud.bigquery.job.QueryJob.from_api_repr
  - google.cloud.bigquery.job.QueryJob.job_id
  - google.cloud.bigquery.job.QueryJob.job_type
  - google.cloud.bigquery.job.QueryJob.labels
  - google.cloud.bigquery.job.QueryJob.location
  - google.cloud.bigquery.job.QueryJob.maximum_billing_tier
  - google.cloud.bigquery.job.QueryJob.maximum_bytes_billed
  - google.cloud.bigquery.job.QueryJob.num_child_jobs
  - google.cloud.bigquery.job.QueryJob.num_dml_affected_rows
  - google.cloud.bigquery.job.QueryJob.parent_job_id
  - google.cloud.bigquery.job.QueryJob.path
  - google.cloud.bigquery.job.QueryJob.priority
  - google.cloud.bigquery.job.QueryJob.project
  - google.cloud.bigquery.job.QueryJob.query
  - google.cloud.bigquery.job.QueryJob.query_parameters
  - google.cloud.bigquery.job.QueryJob.query_plan
  - google.cloud.bigquery.job.QueryJob.range_partitioning
  - google.cloud.bigquery.job.QueryJob.referenced_tables
  - google.cloud.bigquery.job.QueryJob.reload
  - google.cloud.bigquery.job.QueryJob.reservation_usage
  - google.cloud.bigquery.job.QueryJob.result
  - google.cloud.bigquery.job.QueryJob.running
  - google.cloud.bigquery.job.QueryJob.schema
  - google.cloud.bigquery.job.QueryJob.schema_update_options
  - google.cloud.bigquery.job.QueryJob.script_statistics
  - google.cloud.bigquery.job.QueryJob.self_link
  - google.cloud.bigquery.job.QueryJob.session_info
  - google.cloud.bigquery.job.QueryJob.set_exception
  - google.cloud.bigquery.job.QueryJob.set_result
  - google.cloud.bigquery.job.QueryJob.slot_millis
  - google.cloud.bigquery.job.QueryJob.started
  - google.cloud.bigquery.job.QueryJob.state
  - google.cloud.bigquery.job.QueryJob.statement_type
  - google.cloud.bigquery.job.QueryJob.table_definitions
  - google.cloud.bigquery.job.QueryJob.time_partitioning
  - google.cloud.bigquery.job.QueryJob.timeline
  - google.cloud.bigquery.job.QueryJob.to_api_repr
  - google.cloud.bigquery.job.QueryJob.to_arrow
  - google.cloud.bigquery.job.QueryJob.to_dataframe
  - google.cloud.bigquery.job.QueryJob.to_geodataframe
  - google.cloud.bigquery.job.QueryJob.total_bytes_billed
  - google.cloud.bigquery.job.QueryJob.total_bytes_processed
  - google.cloud.bigquery.job.QueryJob.transaction_info
  - google.cloud.bigquery.job.QueryJob.udf_resources
  - google.cloud.bigquery.job.QueryJob.undeclared_query_parameters
  - google.cloud.bigquery.job.QueryJob.use_legacy_sql
  - google.cloud.bigquery.job.QueryJob.use_query_cache
  - google.cloud.bigquery.job.QueryJob.user_email
  - google.cloud.bigquery.job.QueryJob.write_disposition
  - google.cloud.bigquery.job.QueryJob.__init__
  - google.cloud.bigquery.job.QueryJob.bi_engine_stats
  - google.cloud.bigquery.job.QueryJob.dml_stats
  - google.cloud.bigquery.job.QueryJob
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob
  inheritance:
  - inheritance:
    - inheritance:
      - inheritance:
        - type: builtins.object
        type: google.api_core.future.base.Future
      type: google.api_core.future.polling.PollingFuture
    type: google.cloud.bigquery.job.base._AsyncJob
  langs:
  - python
  module: google.cloud.bigquery.job
  name: QueryJob
  source:
    id: QueryJob
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 730
  summary: 'Asynchronous job: query tables.

    '
  syntax:
    content: QueryJob(job_id, query, client, job_config=None)
    parameters:
    - description: the job's ID, within the project belonging to <code>client</code>.
      id: job_id
      var_type: str
    - description: SQL query string.
      id: query
      var_type: str
    - description: A client which holds credentials and project configuration for
        the dataset (which requires a project).
      id: client
      var_type: <xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>
    - description: Extra configuration options for the query job.
      id: job_config
      var_type: Optional[<xref uid="google.cloud.bigquery.job.QueryJobConfig">google.cloud.bigquery.job.QueryJobConfig</xref>]
  type: class
  uid: google.cloud.bigquery.job.QueryJob
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.add_done_callback
  langs:
  - python
  module: google.cloud.bigquery.job
  name: add_done_callback
  source:
    id: add_done_callback
    path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
    remote:
      branch: add_goldens
      path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 155
  summary: 'Add a callback to be executed when the operation is complete.


    If the operation is not already complete, this will start a helper

    thread to poll for the status of the operation in the background.

    '
  syntax:
    content: add_done_callback(fn)
    parameters:
    - description: The callback to execute when the operation is complete.
      id: fn
      var_type: Callable[Future]
  type: method
  uid: google.cloud.bigquery.job.QueryJob.add_done_callback
- &id001
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.allow_large_results
  langs:
  - python
  module: google.cloud.bigquery.job
  name: allow_large_results
  source:
    id: allow_large_results
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.allow_large_results">allow_large_results</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.allow_large_results
- *id001
- &id002
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.billing_tier
  langs:
  - python
  module: google.cloud.bigquery.job
  name: billing_tier
  source:
    id: billing_tier
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return billing tier from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.billing_tier

    '
  syntax:
    returns:
    - description: Billing tier used by the job, or None if job is not yet complete.
      var_type: Optional[int]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.billing_tier
- *id002
- &id003
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.cache_hit
  langs:
  - python
  module: google.cloud.bigquery.job
  name: cache_hit
  source:
    id: cache_hit
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return whether or not query results were served from cache.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.cache_hit

    '
  syntax:
    returns:
    - description: whether the query results were returned from cache, or None if
        job is not yet complete.
      var_type: Optional[bool]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.cache_hit
- *id003
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.cancel
  langs:
  - python
  module: google.cloud.bigquery.job
  name: cancel
  source:
    id: cancel
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 604
  summary: 'API call:  cancel job via a POST request


    See

    https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel

    '
  syntax:
    content: 'cancel(client=None, retry: retries.Retry = <google.api_core.retry.Retry
      object>, timeout: float = None)'
    parameters:
    - description: The number of seconds to wait for the underlying HTTP transport
        before using <code>retry</code>
      id: timeout
      var_type: Optional[float]
    - description: the client to use. If not passed, falls back to the <code>client</code>
        stored on the current dataset.
      id: client
      var_type: Optional[<xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>]
    - description: How to retry the RPC.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
    returns:
    - description: Boolean indicating that the cancel request was sent.
      var_type: bool
  type: method
  uid: google.cloud.bigquery.job.QueryJob.cancel
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.cancelled
  langs:
  - python
  module: google.cloud.bigquery.job
  name: cancelled
  source:
    id: cancelled
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 730
  summary: 'Check if the job has been cancelled.


    This always returns False. It''s not possible to check if a job was

    cancelled in the API. This method is here to satisfy the interface

    for `google.api_core.future.Future`.

    '
  syntax:
    content: cancelled()
    parameters: []
    returns:
    - description: 'False'
      var_type: bool
  type: method
  uid: google.cloud.bigquery.job.QueryJob.cancelled
- &id004
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.clustering_fields
  langs:
  - python
  module: google.cloud.bigquery.job
  name: clustering_fields
  source:
    id: clustering_fields
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.clustering_fields">clustering_fields</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.clustering_fields
- *id004
- &id005
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.connection_properties
  langs:
  - python
  module: google.cloud.bigquery.job
  name: connection_properties
  source:
    id: connection_properties
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.connection_properties">connection_properties</xref>.


    .. versionadded:: 2.29.0


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.connection_properties
- *id005
- &id006
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.create_disposition
  langs:
  - python
  module: google.cloud.bigquery.job
  name: create_disposition
  source:
    id: create_disposition
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.create_disposition">create_disposition</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.create_disposition
- *id006
- &id007
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.create_session
  langs:
  - python
  module: google.cloud.bigquery.job
  name: create_session
  source:
    id: create_session
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.create_session">create_session</xref>.


    .. versionadded:: 2.29.0


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.create_session
- *id007
- &id008
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.created
  langs:
  - python
  module: google.cloud.bigquery.job
  name: created
  source:
    id: created
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Datetime at which the job was created.

    '
  syntax:
    returns:
    - description: the creation time (None until set from the server).
      var_type: Optional[datetime.datetime]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.created
- *id008
- &id009
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.ddl_operation_performed
  langs:
  - python
  module: google.cloud.bigquery.job
  name: ddl_operation_performed
  source:
    id: ddl_operation_performed
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Optional[str]: Return the DDL operation performed.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_operation_performed


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.ddl_operation_performed
- *id009
- &id010
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.ddl_target_routine
  langs:
  - python
  module: google.cloud.bigquery.job
  name: ddl_target_routine
  source:
    id: ddl_target_routine
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: "Optional[<xref uid=\"google.cloud.bigquery.routine.RoutineReference\"\
    >google.cloud.bigquery.routine.RoutineReference</xref>]: Return the DDL target\
    \ routine, present\n    for CREATE/DROP FUNCTION/PROCEDURE  queries.\n\nSee:\n\
    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_target_routine\n\
    \n"
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.ddl_target_routine
- *id010
- &id011
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.ddl_target_table
  langs:
  - python
  module: google.cloud.bigquery.job
  name: ddl_target_table
  source:
    id: ddl_target_table
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: "Optional[<xref uid=\"google.cloud.bigquery.table.TableReference\">google.cloud.bigquery.table.TableReference</xref>]:\
    \ Return the DDL target table, present\n    for CREATE/DROP TABLE/VIEW queries.\n\
    \nSee:\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_target_table\n\
    \n"
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.ddl_target_table
- *id011
- &id012
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.default_dataset
  langs:
  - python
  module: google.cloud.bigquery.job
  name: default_dataset
  source:
    id: default_dataset
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.default_dataset">default_dataset</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.default_dataset
- *id012
- &id013
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.destination
  langs:
  - python
  module: google.cloud.bigquery.job
  name: destination
  source:
    id: destination
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.destination">destination</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.destination
- *id013
- &id014
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.destination_encryption_configuration
  langs:
  - python
  module: google.cloud.bigquery.job
  name: destination_encryption_configuration
  source:
    id: destination_encryption_configuration
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: '<xref uid="google.cloud.bigquery.encryption_configuration.EncryptionConfiguration">google.cloud.bigquery.encryption_configuration.EncryptionConfiguration</xref>:
    Custom

    encryption configuration for the destination table.


    Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`

    if using default encryption.


    See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.destination_encryption_configuration">destination_encryption_configuration</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.destination_encryption_configuration
- *id014
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.done
  langs:
  - python
  module: google.cloud.bigquery.job
  name: done
  source:
    id: done
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 672
  summary: 'Checks if the job is complete.

    '
  syntax:
    content: 'done(retry: retries.Retry = <google.api_core.retry.Retry object>, timeout:
      float = None, reload: bool = True)'
    parameters:
    - defaultValue: None
      description: The number of seconds to wait for the underlying HTTP transport
        before using <code>retry</code>.
      id: timeout
      var_type: Optional[float]
    - defaultValue: 'True'
      description: If <code>True</code>, make an API call to refresh the job state
        of unfinished jobs before checking. Default <code>True</code>.
      id: reload
      var_type: Optional[bool]
    - description: How to retry the RPC. If the job state is <code>DONE</code>, retrying
        is aborted early, as the job will not change anymore.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
    returns:
    - description: True if the job is complete, False otherwise.
      var_type: bool
  type: method
  uid: google.cloud.bigquery.job.QueryJob.done
- &id015
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.dry_run
  langs:
  - python
  module: google.cloud.bigquery.job
  name: dry_run
  source:
    id: dry_run
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.dry_run">dry_run</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.dry_run
- *id015
- &id016
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.ended
  langs:
  - python
  module: google.cloud.bigquery.job
  name: ended
  source:
    id: ended
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Datetime at which the job finished.

    '
  syntax:
    returns:
    - description: the end time (None until set from the server).
      var_type: Optional[datetime.datetime]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.ended
- *id016
- &id017
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.error_result
  langs:
  - python
  module: google.cloud.bigquery.job
  name: error_result
  source:
    id: error_result
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Error information about the job as a whole.

    '
  syntax:
    returns:
    - description: the error information (None until set from the server).
      var_type: Optional[Mapping]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.error_result
- *id017
- &id018
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.errors
  langs:
  - python
  module: google.cloud.bigquery.job
  name: errors
  source:
    id: errors
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Information about individual errors generated by the job.

    '
  syntax:
    returns:
    - description: the error information (None until set from the server).
      var_type: Optional[List[Mapping]]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.errors
- *id018
- &id019
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.estimated_bytes_processed
  langs:
  - python
  module: google.cloud.bigquery.job
  name: estimated_bytes_processed
  source:
    id: estimated_bytes_processed
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return the estimated number of bytes processed by the query.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.estimated_bytes_processed

    '
  syntax:
    returns:
    - description: number of DML rows affected by the job, or None if job is not yet
        complete.
      var_type: Optional[int]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.estimated_bytes_processed
- *id019
- &id020
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.etag
  langs:
  - python
  module: google.cloud.bigquery.job
  name: etag
  source:
    id: etag
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'ETag for the job resource.

    '
  syntax:
    returns:
    - description: the ETag (None until set from the server).
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.etag
- *id020
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.exception
  langs:
  - python
  module: google.cloud.bigquery.job
  name: exception
  source:
    id: exception
    path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
    remote:
      branch: add_goldens
      path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 141
  summary: 'Get the exception from the operation, blocking if necessary.

    '
  syntax:
    content: exception(timeout=None)
    parameters:
    - description: How long to wait for the operation to complete. If None, wait indefinitely.
      id: timeout
      var_type: int
    returns:
    - description: The operation's error.
      var_type: Optional[google.api_core.GoogleAPICallError]
  type: method
  uid: google.cloud.bigquery.job.QueryJob.exception
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.exists
  langs:
  - python
  module: google.cloud.bigquery.job
  name: exists
  source:
    id: exists
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 522
  summary: 'API call:  test for the existence of the job via a GET request


    See

    https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get

    '
  syntax:
    content: 'exists(client=None, retry: retries.Retry = <google.api_core.retry.Retry
      object>, timeout: float = None)'
    parameters:
    - description: The number of seconds to wait for the underlying HTTP transport
        before using <code>retry</code>.
      id: timeout
      var_type: Optional[float]
    - description: the client to use. If not passed, falls back to the <code>client</code>
        stored on the current dataset.
      id: client
      var_type: Optional[<xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>]
    - description: How to retry the RPC.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
    returns:
    - description: Boolean indicating existence of the job.
      var_type: bool
  type: method
  uid: google.cloud.bigquery.job.QueryJob.exists
- &id021
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.flatten_results
  langs:
  - python
  module: google.cloud.bigquery.job
  name: flatten_results
  source:
    id: flatten_results
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.flatten_results">flatten_results</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.flatten_results
- *id021
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.from_api_repr
  langs:
  - python
  module: google.cloud.bigquery.job
  name: from_api_repr
  source:
    id: from_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 954
  summary: 'Factory:  construct a job given its API representation

    '
  syntax:
    content: 'from_api_repr(resource: dict, client: Client)'
    parameters:
    - description: dataset job representation returned from the API
      id: resource
      var_type: Dict
    - description: Client which holds credentials and project configuration for the
        dataset.
      id: client
      var_type: <xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>
    returns:
    - description: Job parsed from <code>resource</code>.
      var_type: google.cloud.bigquery.job.QueryJob
  type: method
  uid: google.cloud.bigquery.job.QueryJob.from_api_repr
- &id022
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.job_id
  langs:
  - python
  module: google.cloud.bigquery.job
  name: job_id
  source:
    id: job_id
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: ID of the job.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.job_id
- *id022
- &id023
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.job_type
  langs:
  - python
  module: google.cloud.bigquery.job
  name: job_type
  source:
    id: job_type
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Type of job.

    '
  syntax:
    returns:
    - description: one of 'load', 'copy', 'extract', 'query'.
      var_type: str
  type: property
  uid: google.cloud.bigquery.job.QueryJob.job_type
- *id023
- &id024
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.labels
  langs:
  - python
  module: google.cloud.bigquery.job
  name: labels
  source:
    id: labels
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Dict[str, str]: Labels for the job.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.labels
- *id024
- &id025
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.location
  langs:
  - python
  module: google.cloud.bigquery.job
  name: location
  source:
    id: location
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: Location where the job runs.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.location
- *id025
- &id026
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.maximum_billing_tier
  langs:
  - python
  module: google.cloud.bigquery.job
  name: maximum_billing_tier
  source:
    id: maximum_billing_tier
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.maximum_billing_tier">maximum_billing_tier</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.maximum_billing_tier
- *id026
- &id027
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.maximum_bytes_billed
  langs:
  - python
  module: google.cloud.bigquery.job
  name: maximum_bytes_billed
  source:
    id: maximum_bytes_billed
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.maximum_bytes_billed">maximum_bytes_billed</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.maximum_bytes_billed
- *id027
- &id028
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.num_child_jobs
  langs:
  - python
  module: google.cloud.bigquery.job
  name: num_child_jobs
  source:
    id: num_child_jobs
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'The number of child jobs executed.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs

    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.num_child_jobs
- *id028
- &id029
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.num_dml_affected_rows
  langs:
  - python
  module: google.cloud.bigquery.job
  name: num_dml_affected_rows
  source:
    id: num_dml_affected_rows
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return the number of DML rows affected by the job.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.num_dml_affected_rows

    '
  syntax:
    returns:
    - description: number of DML rows affected by the job, or None if job is not yet
        complete.
      var_type: Optional[int]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.num_dml_affected_rows
- *id029
- &id030
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.parent_job_id
  langs:
  - python
  module: google.cloud.bigquery.job
  name: parent_job_id
  source:
    id: parent_job_id
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return the ID of the parent job.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id

    '
  syntax:
    returns:
    - description: parent job id.
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.parent_job_id
- *id030
- &id031
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.path
  langs:
  - python
  module: google.cloud.bigquery.job
  name: path
  source:
    id: path
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'URL path for the job''s APIs.

    '
  syntax:
    returns:
    - description: the path based on project and job ID.
      var_type: str
  type: property
  uid: google.cloud.bigquery.job.QueryJob.path
- *id031
- &id032
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.priority
  langs:
  - python
  module: google.cloud.bigquery.job
  name: priority
  source:
    id: priority
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.priority">priority</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.priority
- *id032
- &id033
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.project
  langs:
  - python
  module: google.cloud.bigquery.job
  name: project
  source:
    id: project
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Project bound to the job.

    '
  syntax:
    returns:
    - description: the project (derived from the client).
      var_type: str
  type: property
  uid: google.cloud.bigquery.job.QueryJob.project
- *id033
- &id034
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.query
  langs:
  - python
  module: google.cloud.bigquery.job
  name: query
  source:
    id: query
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'str: The query text used in this query job.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.query


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.query
- *id034
- &id035
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.query_parameters
  langs:
  - python
  module: google.cloud.bigquery.job
  name: query_parameters
  source:
    id: query_parameters
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.query_parameters">query_parameters</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.query_parameters
- *id035
- &id036
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.query_plan
  langs:
  - python
  module: google.cloud.bigquery.job
  name: query_plan
  source:
    id: query_plan
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return query plan from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.query_plan

    '
  syntax:
    returns:
    - description: mappings describing the query plan, or an empty list if the query
        has not yet completed.
      var_type: List[<xref uid="google.cloud.bigquery.job.QueryPlanEntry">google.cloud.bigquery.job.QueryPlanEntry</xref>]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.query_plan
- *id036
- &id037
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.range_partitioning
  langs:
  - python
  module: google.cloud.bigquery.job
  name: range_partitioning
  source:
    id: range_partitioning
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.range_partitioning">range_partitioning</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.range_partitioning
- *id037
- &id038
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.referenced_tables
  langs:
  - python
  module: google.cloud.bigquery.job
  name: referenced_tables
  source:
    id: referenced_tables
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return referenced tables from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.referenced_tables

    '
  syntax:
    returns:
    - description: mappings describing the query plan, or an empty list if the query
        has not yet completed.
      var_type: List[Dict]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.referenced_tables
- *id038
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.reload
  langs:
  - python
  module: google.cloud.bigquery.job
  name: reload
  source:
    id: reload
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/base.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 567
  summary: 'API call:  refresh job properties via a GET request.


    See

    https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get

    '
  syntax:
    content: 'reload(client=None, retry: retries.Retry = <google.api_core.retry.Retry
      object>, timeout: float = None)'
    parameters:
    - description: The number of seconds to wait for the underlying HTTP transport
        before using <code>retry</code>.
      id: timeout
      var_type: Optional[float]
    - description: the client to use. If not passed, falls back to the <code>client</code>
        stored on the current dataset.
      id: client
      var_type: Optional[<xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>]
    - description: How to retry the RPC.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
  type: method
  uid: google.cloud.bigquery.job.QueryJob.reload
- &id039
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.reservation_usage
  langs:
  - python
  module: google.cloud.bigquery.job
  name: reservation_usage
  source:
    id: reservation_usage
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Job resource usage breakdown by reservation.

    '
  syntax:
    returns:
    - description: Reservation usage stats. Can be empty if not set from the server.
      var_type: List[<xref uid="google.cloud.bigquery.job.ReservationUsage">google.cloud.bigquery.job.ReservationUsage</xref>]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.reservation_usage
- *id039
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.result
  langs:
  - python
  module: google.cloud.bigquery.job
  name: result
  source:
    id: result
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 1382
  summary: 'Start the job and wait for it to complete and get the result.

    '
  syntax:
    content: 'result(page_size: int = None, max_results: int = None, retry: retries.Retry
      = <google.api_core.retry.Retry object>, timeout: float = None, start_index:
      int = None, job_retry: retries.Retry = <google.api_core.retry.Retry object>)'
    exceptions:
    - description: If the job failed and retries aren't successful.
      var_type: google.cloud.exceptions.GoogleAPICallError
    - description: If the job did not complete in the given timeout.
      var_type: concurrent.futures.TimeoutError
    - description: If Non-<code>None</code> and non-default <code>job_retry</code>
        is provided and the job is not retryable.
      var_type: TypeError
    parameters:
    - defaultValue: <Retry predicate=<function _should_retry at 0x7fd9179a2a60>, initial=1.0,
        maximum=60.0, multiplier=2.0, deadline=600.0, on_error=None>
      description: The maximum number of rows in each page of results from this request.
        Non-positive values are ignored.
      id: page_size
      var_type: Optional[int]
    - defaultValue: None
      description: The maximum total number of rows from this request.
      id: max_results
      var_type: Optional[int]
    - defaultValue: None
      description: The number of seconds to wait for the underlying HTTP transport
        before using <code>retry</code>. If multiple requests are made under the hood,
        <code>timeout</code> applies to each individual request.
      id: timeout
      var_type: Optional[float]
    - defaultValue: <Retry predicate=<function _job_should_retry at 0x7fd9179a2af0>,
        initial=1.0, maximum=60.0, multiplier=2.0, deadline=600.0, on_error=None>
      description: The zero-based index of the starting row to read.
      id: start_index
      var_type: Optional[int]
    - description: How to retry the call that retrieves rows. This only applies to
        making RPC calls. It isn't used to retry failed jobs. This has a reasonable
        default that should only be overridden with care. If the job state is <code>DONE</code>,
        retrying is aborted early even if the results are not available, as this will
        not change anymore.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
    - description: How to retry failed jobs. The default retries rate-limit-exceeded
        errors. Passing <code>None</code> disables job retry. Not all jobs can be
        retried. If <code>job_id</code> was provided to the query that created this
        job, then the job returned by the query will not be retryable, and an exception
        will be raised if non-<code>None</code> non-default <code>job_retry</code>
        is also provided.
      id: job_retry
      var_type: Optional[google.api_core.retry.Retry]
    returns:
    - description: 'Iterator of row data <xref uid="google.cloud.bigquery.table.Row">Row</xref>-s.
        During each page, the iterator will have the <code>total_rows</code> attribute
        set, which counts the total number of rows **in the result set** (this is
        distinct from the total number of rows in the current page: <code>iterator.page.num_items</code>).
        If the query is a special query that produces no results, e.g. a DDL query,
        an <code>_EmptyRowIterator</code> instance is returned.'
      var_type: <xref uid="google.cloud.bigquery.table.RowIterator">google.cloud.bigquery.table.RowIterator</xref>
  type: method
  uid: google.cloud.bigquery.job.QueryJob.result
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.running
  langs:
  - python
  module: google.cloud.bigquery.job
  name: running
  source:
    id: running
    path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
    remote:
      branch: add_goldens
      path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 91
  summary: 'True if the operation is currently running.


    '
  syntax:
    content: running()
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.QueryJob.running
- &id040
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.schema
  langs:
  - python
  module: google.cloud.bigquery.job
  name: schema
  source:
    id: schema
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'The schema of the results.


    Present only for successful dry run of non-legacy SQL queries.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.schema
- *id040
- &id041
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.schema_update_options
  langs:
  - python
  module: google.cloud.bigquery.job
  name: schema_update_options
  source:
    id: schema_update_options
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.schema_update_options">schema_update_options</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.schema_update_options
- *id041
- &id042
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.script_statistics
  langs:
  - python
  module: google.cloud.bigquery.job
  name: script_statistics
  source:
    id: script_statistics
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Statistics for a child job of a script.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.script_statistics
- *id042
- &id043
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.self_link
  langs:
  - python
  module: google.cloud.bigquery.job
  name: self_link
  source:
    id: self_link
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'URL for the job resource.

    '
  syntax:
    returns:
    - description: the URL (None until set from the server).
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.self_link
- *id043
- &id044
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.session_info
  langs:
  - python
  module: google.cloud.bigquery.job
  name: session_info
  source:
    id: session_info
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: '[Preview] Information of the session if this job is part of one.


    .. versionadded:: 2.29.0


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.session_info
- *id044
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.set_exception
  langs:
  - python
  module: google.cloud.bigquery.job
  name: set_exception
  source:
    id: set_exception
    path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
    remote:
      branch: add_goldens
      path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 189
  summary: 'Set the Future''s exception.


    '
  syntax:
    content: set_exception(exception)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.QueryJob.set_exception
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.set_result
  langs:
  - python
  module: google.cloud.bigquery.job
  name: set_result
  source:
    id: set_result
    path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
    remote:
      branch: add_goldens
      path: .tox/update_goldens/lib/python3.9/site-packages/google/api_core/future/polling.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 183
  summary: 'Set the Future''s result.


    '
  syntax:
    content: set_result(result)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.QueryJob.set_result
- &id045
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.slot_millis
  langs:
  - python
  module: google.cloud.bigquery.job
  name: slot_millis
  source:
    id: slot_millis
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Union[int, None]: Slot-milliseconds used by this query job.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.slot_millis
- *id045
- &id046
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.started
  langs:
  - python
  module: google.cloud.bigquery.job
  name: started
  source:
    id: started
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Datetime at which the job was started.

    '
  syntax:
    returns:
    - description: the start time (None until set from the server).
      var_type: Optional[datetime.datetime]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.started
- *id046
- &id047
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.state
  langs:
  - python
  module: google.cloud.bigquery.job
  name: state
  source:
    id: state
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Status of the job.

    '
  syntax:
    returns:
    - description: the state (None until set from the server).
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.state
- *id047
- &id048
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.statement_type
  langs:
  - python
  module: google.cloud.bigquery.job
  name: statement_type
  source:
    id: statement_type
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return statement type from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.statement_type

    '
  syntax:
    returns:
    - description: type of statement used by the job, or None if job is not yet complete.
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.statement_type
- *id048
- &id049
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.table_definitions
  langs:
  - python
  module: google.cloud.bigquery.job
  name: table_definitions
  source:
    id: table_definitions
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.table_definitions">table_definitions</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.table_definitions
- *id049
- &id050
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.time_partitioning
  langs:
  - python
  module: google.cloud.bigquery.job
  name: time_partitioning
  source:
    id: time_partitioning
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.time_partitioning">time_partitioning</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.time_partitioning
- *id050
- &id051
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.timeline
  langs:
  - python
  module: google.cloud.bigquery.job
  name: timeline
  source:
    id: timeline
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'List(TimelineEntry): Return the query execution timeline

    from job statistics.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.timeline
- *id051
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.to_api_repr
  langs:
  - python
  module: google.cloud.bigquery.job
  name: to_api_repr
  source:
    id: to_api_repr
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 944
  summary: 'Generate a resource for `_begin`.


    '
  syntax:
    content: to_api_repr()
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.QueryJob.to_api_repr
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.to_arrow
  langs:
  - python
  module: google.cloud.bigquery.job
  name: to_arrow
  source:
    id: to_arrow
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 1537
  summary: '[Beta] Create a class:`pyarrow.Table` by loading all pages of a

    table or query.

    '
  syntax:
    content: "to_arrow(\n    progress_bar_type: str = None,\n    bqstorage_client:\
      \ typing.Optional[bigquery_storage.BigQueryReadClient] = None,\n    create_bqstorage_client:\
      \ bool = True,\n    max_results: typing.Optional[int] = None,\n)"
    parameters:
    - defaultValue: None
      description: 'If set, use the <code>tqdm <https://tqdm.github.io/></code>_ library
        to display a progress bar while the data downloads. Install the <code>tqdm</code>
        package to use this feature. Possible values of <code>progress_bar_type</code>
        include: <code>None</code> No progress bar. <code>''tqdm''</code> Use the
        <code>tqdm.tqdm</code> function to print a progress bar to :data:<code>sys.stdout</code>.
        <code>''tqdm_notebook''</code> Use the <code>tqdm.notebook.tqdm</code> function
        to display a progress bar as a Jupyter notebook widget. <code>''tqdm_gui''</code>
        Use the <code>tqdm.tqdm_gui</code> function to display a progress bar as a
        graphical dialog box.'
      id: progress_bar_type
      var_type: Optional[str]
    - defaultValue: None
      description: A BigQuery Storage API client. If supplied, use the faster BigQuery
        Storage API to fetch rows from BigQuery. This API is a billable API. This
        method requires <code>google-cloud-bigquery-storage</code> library. Reading
        from a specific partition or snapshot is not currently supported by this method.
      id: bqstorage_client
      var_type: Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]
    - defaultValue: 'True'
      description: 'If <code>True</code> (default), create a BigQuery Storage API
        client using the default API settings. The BigQuery Storage API is a faster
        way to fetch rows from BigQuery. See the <code>bqstorage_client</code> parameter
        for more information. This argument does nothing if <code>bqstorage_client</code>
        is supplied. .. versionadded:: 1.24.0'
      id: create_bqstorage_client
      var_type: Optional[bool]
    - defaultValue: None
      description: 'Maximum number of rows to include in the result. No limit by default.
        .. versionadded:: 2.21.0'
      id: max_results
      var_type: Optional[int]
  type: method
  uid: google.cloud.bigquery.job.QueryJob.to_arrow
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.to_dataframe
  langs:
  - python
  module: google.cloud.bigquery.job
  name: to_dataframe
  source:
    id: to_dataframe
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 1608
  summary: 'Return a pandas DataFrame from a QueryJob

    '
  syntax:
    content: "to_dataframe(\n    bqstorage_client: typing.Optional[bigquery_storage.BigQueryReadClient]\
      \ = None,\n    dtypes: typing.Dict[str, typing.Any] = None,\n    progress_bar_type:\
      \ str = None,\n    create_bqstorage_client: bool = True,\n    max_results: typing.Optional[int]\
      \ = None,\n    geography_as_object: bool = False,\n)"
    exceptions:
    - description: If the <code>pandas</code> library cannot be imported, or the <xref
        uid="google.cloud.bigquery_storage_v1">bigquery_storage_v1</xref> module is
        required but cannot be imported. Also if <code>geography_as_object</code>
        is <code>True</code>, but the <code>shapely</code> library cannot be imported.
      var_type: ValueError
    parameters:
    - defaultValue: None
      description: A BigQuery Storage API client. If supplied, use the faster BigQuery
        Storage API to fetch rows from BigQuery. This API is a billable API. This
        method requires the <code>fastavro</code> and <code>google-cloud-bigquery-storage</code>
        libraries. Reading from a specific partition or snapshot is not currently
        supported by this method.
      id: bqstorage_client
      var_type: Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]
    - defaultValue: None
      description: A dictionary of column names pandas <code>dtype</code>s. The provided
        <code>dtype</code> is used when constructing the series for the column specified.
        Otherwise, the default pandas behavior is used.
      id: dtypes
      var_type: Optional[Map[str, Union[str, pandas.Series.dtype]]]
    - defaultValue: None
      description: 'If set, use the <code>tqdm <https://tqdm.github.io/></code>_ library
        to display a progress bar while the data downloads. Install the <code>tqdm</code>
        package to use this feature. See <xref uid="google.cloud.bigquery.table.RowIterator.to_dataframe">to_dataframe</xref>
        for details. .. versionadded:: 1.11.0'
      id: progress_bar_type
      var_type: Optional[str]
    - defaultValue: 'True'
      description: 'If <code>True</code> (default), create a BigQuery Storage API
        client using the default API settings. The BigQuery Storage API is a faster
        way to fetch rows from BigQuery. See the <code>bqstorage_client</code> parameter
        for more information. This argument does nothing if <code>bqstorage_client</code>
        is supplied. .. versionadded:: 1.24.0'
      id: create_bqstorage_client
      var_type: Optional[bool]
    - defaultValue: None
      description: 'Maximum number of rows to include in the result. No limit by default.
        .. versionadded:: 2.21.0'
      id: max_results
      var_type: Optional[int]
    - defaultValue: 'False'
      description: 'If <code>True</code>, convert GEOGRAPHY data to <code>shapely</code>
        geometry objects. If <code>False</code> (default), don''t cast geography data
        to <code>shapely</code> geometry objects. .. versionadded:: 2.24.0'
      id: geography_as_object
      var_type: Optional[bool]
    returns:
    - description: A <code>pandas.DataFrame</code> populated with row data and column
        headers from the query results. The column headers are derived from the destination
        table's schema.
      var_type: pandas.DataFrame
  type: method
  uid: google.cloud.bigquery.job.QueryJob.to_dataframe
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.to_geodataframe
  langs:
  - python
  module: google.cloud.bigquery.job
  name: to_geodataframe
  source:
    id: to_geodataframe
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 1695
  summary: 'Return a GeoPandas GeoDataFrame from a QueryJob

    '
  syntax:
    content: "to_geodataframe(\n    bqstorage_client: bigquery_storage.BigQueryReadClient\
      \ = None,\n    dtypes: typing.Dict[str, typing.Any] = None,\n    progress_bar_type:\
      \ str = None,\n    create_bqstorage_client: bool = True,\n    max_results: typing.Optional[int]\
      \ = None,\n    geography_column: typing.Optional[str] = None,\n)"
    exceptions:
    - description: 'If the <code>geopandas</code> library cannot be imported, or the
        <xref uid="google.cloud.bigquery_storage_v1">bigquery_storage_v1</xref> module
        is required but cannot be imported. .. versionadded:: 2.24.0'
      var_type: ValueError
    parameters:
    - defaultValue: None
      description: A dictionary of column names pandas <code>dtype</code>s. The provided
        <code>dtype</code> is used when constructing the series for the column specified.
        Otherwise, the default pandas behavior is used.
      id: dtypes
      var_type: Optional[Map[str, Union[str, pandas.Series.dtype]]]
    - defaultValue: None
      description: 'If set, use the <code>tqdm <https://tqdm.github.io/></code>_ library
        to display a progress bar while the data downloads. Install the <code>tqdm</code>
        package to use this feature. See <xref uid="google.cloud.bigquery.table.RowIterator.to_dataframe">to_dataframe</xref>
        for details. .. versionadded:: 1.11.0'
      id: progress_bar_type
      var_type: Optional[str]
    - defaultValue: 'True'
      description: 'If <code>True</code> (default), create a BigQuery Storage API
        client using the default API settings. The BigQuery Storage API is a faster
        way to fetch rows from BigQuery. See the <code>bqstorage_client</code> parameter
        for more information. This argument does nothing if <code>bqstorage_client</code>
        is supplied. .. versionadded:: 1.24.0'
      id: create_bqstorage_client
      var_type: Optional[bool]
    - defaultValue: None
      description: 'Maximum number of rows to include in the result. No limit by default.
        .. versionadded:: 2.21.0'
      id: max_results
      var_type: Optional[int]
    - defaultValue: None
      description: If there are more than one GEOGRAPHY column, identifies which one
        to use to construct a GeoPandas GeoDataFrame. This option can be ommitted
        if there's only one GEOGRAPHY column.
      id: geography_column
      var_type: Optional[str]
    - description: A BigQuery Storage API client. If supplied, use the faster BigQuery
        Storage API to fetch rows from BigQuery. This API is a billable API. This
        method requires the <code>fastavro</code> and <code>google-cloud-bigquery-storage</code>
        libraries. Reading from a specific partition or snapshot is not currently
        supported by this method.
      id: bqstorage_client
      var_type: Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]
    returns:
    - description: A <code>geopandas.GeoDataFrame</code> populated with row data and
        column headers from the query results. The column headers are derived from
        the destination table's schema.
      var_type: geopandas.GeoDataFrame
  type: method
  uid: google.cloud.bigquery.job.QueryJob.to_geodataframe
- &id052
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.total_bytes_billed
  langs:
  - python
  module: google.cloud.bigquery.job
  name: total_bytes_billed
  source:
    id: total_bytes_billed
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return total bytes billed from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.total_bytes_billed

    '
  syntax:
    returns:
    - description: Total bytes processed by the job, or None if job is not yet complete.
      var_type: Optional[int]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.total_bytes_billed
- *id052
- &id053
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.total_bytes_processed
  langs:
  - python
  module: google.cloud.bigquery.job
  name: total_bytes_processed
  source:
    id: total_bytes_processed
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return total bytes processed from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.total_bytes_processed

    '
  syntax:
    returns:
    - description: Total bytes processed by the job, or None if job is not yet complete.
      var_type: Optional[int]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.total_bytes_processed
- *id053
- &id054
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.transaction_info
  langs:
  - python
  module: google.cloud.bigquery.job
  name: transaction_info
  source:
    id: transaction_info
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Information of the multi-statement transaction if this job is part of
    one.


    Since a scripting query job can execute multiple transactions, this

    property is only expected on child jobs. Use the

    <xref uid="google.cloud.bigquery.client.Client.list_jobs">list_jobs</xref> method
    with the

    `parent_job` parameter to iterate over child jobs.


    .. versionadded:: 2.24.0


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.transaction_info
- *id054
- &id055
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.udf_resources
  langs:
  - python
  module: google.cloud.bigquery.job
  name: udf_resources
  source:
    id: udf_resources
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.udf_resources">udf_resources</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.udf_resources
- *id055
- &id056
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.undeclared_query_parameters
  langs:
  - python
  module: google.cloud.bigquery.job
  name: undeclared_query_parameters
  source:
    id: undeclared_query_parameters
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'Return undeclared query parameters from job statistics, if present.


    See:

    https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.undeclared_query_parameters

    '
  syntax:
    returns:
    - description: Undeclared parameters, or an empty list if the query has not yet
        completed.
      var_type: List[Union[ <xref uid="google.cloud.bigquery.query.ArrayQueryParameter">google.cloud.bigquery.query.ArrayQueryParameter</xref>,
        <xref uid="google.cloud.bigquery.query.ScalarQueryParameter">google.cloud.bigquery.query.ScalarQueryParameter</xref>,
        <xref uid="google.cloud.bigquery.query.StructQueryParameter">google.cloud.bigquery.query.StructQueryParameter</xref>
        ]]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.undeclared_query_parameters
- *id056
- &id057
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.use_legacy_sql
  langs:
  - python
  module: google.cloud.bigquery.job
  name: use_legacy_sql
  source:
    id: use_legacy_sql
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.use_legacy_sql">use_legacy_sql</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.use_legacy_sql
- *id057
- &id058
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.use_query_cache
  langs:
  - python
  module: google.cloud.bigquery.job
  name: use_query_cache
  source:
    id: use_query_cache
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.use_query_cache">use_query_cache</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.use_query_cache
- *id058
- &id059
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.user_email
  langs:
  - python
  module: google.cloud.bigquery.job
  name: user_email
  source:
    id: user_email
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'E-mail address of user who submitted the job.

    '
  syntax:
    returns:
    - description: the URL (None until set from the server).
      var_type: Optional[str]
  type: property
  uid: google.cloud.bigquery.job.QueryJob.user_email
- *id059
- &id060
  attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.write_disposition
  langs:
  - python
  module: google.cloud.bigquery.job
  name: write_disposition
  source:
    id: write_disposition
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: 'See

    <xref uid="google.cloud.bigquery.job.QueryJobConfig.write_disposition">write_disposition</xref>.


    '
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.write_disposition
- *id060
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.__init__
  langs:
  - python
  module: google.cloud.bigquery.job
  name: __init__
  source:
    id: __init__
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 749
  summary: 'Initialize self.  See help(type(self)) for accurate signature.


    '
  syntax:
    content: __init__(job_id, query, client, job_config=None)
    parameters: []
  type: method
  uid: google.cloud.bigquery.job.QueryJob.__init__
- &id061
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.bi_engine_stats
  langs:
  - python
  module: google.cloud.bigquery.job
  name: bi_engine_stats
  source:
    id: bi_engine_stats
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: API documentation for `bigquery.job.QueryJob.bi_engine_stats` property.
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.bi_engine_stats
- *id061
- &id062
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob.dml_stats
  langs:
  - python
  module: google.cloud.bigquery.job
  name: dml_stats
  source:
    id: dml_stats
    path: null
    remote:
      branch: add_goldens
      path: null
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: null
  summary: API documentation for `bigquery.job.QueryJob.dml_stats` property.
  syntax: {}
  type: property
  uid: google.cloud.bigquery.job.QueryJob.dml_stats
- *id062
- attributes: []
  class: google.cloud.bigquery.job.QueryJob
  fullName: google.cloud.bigquery.job.QueryJob
  inheritance:
  - inheritance:
    - inheritance:
      - inheritance:
        - type: builtins.object
        type: google.api_core.future.base.Future
      type: google.api_core.future.polling.PollingFuture
    type: google.cloud.bigquery.job.base._AsyncJob
  langs:
  - python
  module: google.cloud.bigquery.job
  name: QueryJob
  source:
    id: QueryJob
    path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
    remote:
      branch: add_goldens
      path: tests/testdata/gapic-combo/google/cloud/bigquery/job/query.py
      repo: git@github.com:googleapis/sphinx-docfx-yaml.git
    startLine: 730
  summary: 'Asynchronous job: query tables.

    '
  syntax:
    content: QueryJob(job_id, query, client, job_config=None)
    parameters:
    - description: the job's ID, within the project belonging to <code>client</code>.
      id: job_id
      var_type: str
    - description: SQL query string.
      id: query
      var_type: str
    - description: A client which holds credentials and project configuration for
        the dataset (which requires a project).
      id: client
      var_type: <xref uid="google.cloud.bigquery.client.Client">google.cloud.bigquery.client.Client</xref>
    - description: Extra configuration options for the query job.
      id: job_config
      var_type: Optional[<xref uid="google.cloud.bigquery.job.QueryJobConfig">google.cloud.bigquery.job.QueryJobConfig</xref>]
  type: method
  uid: google.cloud.bigquery.job.QueryJob
references:
- fullName: google.cloud.bigquery.job.QueryJob.add_done_callback
  isExternal: false
  name: add_done_callback
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.add_done_callback
- fullName: google.cloud.bigquery.job.QueryJob.allow_large_results
  isExternal: false
  name: allow_large_results
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.allow_large_results
- fullName: google.cloud.bigquery.job.QueryJob.billing_tier
  isExternal: false
  name: billing_tier
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.billing_tier
- fullName: google.cloud.bigquery.job.QueryJob.cache_hit
  isExternal: false
  name: cache_hit
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.cache_hit
- fullName: google.cloud.bigquery.job.QueryJob.cancel
  isExternal: false
  name: cancel
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.cancel
- fullName: google.cloud.bigquery.job.QueryJob.cancelled
  isExternal: false
  name: cancelled
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.cancelled
- fullName: google.cloud.bigquery.job.QueryJob.clustering_fields
  isExternal: false
  name: clustering_fields
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.clustering_fields
- fullName: google.cloud.bigquery.job.QueryJob.connection_properties
  isExternal: false
  name: connection_properties
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.connection_properties
- fullName: google.cloud.bigquery.job.QueryJob.create_disposition
  isExternal: false
  name: create_disposition
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.create_disposition
- fullName: google.cloud.bigquery.job.QueryJob.create_session
  isExternal: false
  name: create_session
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.create_session
- fullName: google.cloud.bigquery.job.QueryJob.created
  isExternal: false
  name: created
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.created
- fullName: google.cloud.bigquery.job.QueryJob.ddl_operation_performed
  isExternal: false
  name: ddl_operation_performed
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.ddl_operation_performed
- fullName: google.cloud.bigquery.job.QueryJob.ddl_target_routine
  isExternal: false
  name: ddl_target_routine
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.ddl_target_routine
- fullName: google.cloud.bigquery.job.QueryJob.ddl_target_table
  isExternal: false
  name: ddl_target_table
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.ddl_target_table
- fullName: google.cloud.bigquery.job.QueryJob.default_dataset
  isExternal: false
  name: default_dataset
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.default_dataset
- fullName: google.cloud.bigquery.job.QueryJob.destination
  isExternal: false
  name: destination
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.destination
- fullName: google.cloud.bigquery.job.QueryJob.destination_encryption_configuration
  isExternal: false
  name: destination_encryption_configuration
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.destination_encryption_configuration
- fullName: google.cloud.bigquery.job.QueryJob.done
  isExternal: false
  name: done
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.done
- fullName: google.cloud.bigquery.job.QueryJob.dry_run
  isExternal: false
  name: dry_run
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.dry_run
- fullName: google.cloud.bigquery.job.QueryJob.ended
  isExternal: false
  name: ended
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.ended
- fullName: google.cloud.bigquery.job.QueryJob.error_result
  isExternal: false
  name: error_result
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.error_result
- fullName: google.cloud.bigquery.job.QueryJob.errors
  isExternal: false
  name: errors
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.errors
- fullName: google.cloud.bigquery.job.QueryJob.estimated_bytes_processed
  isExternal: false
  name: estimated_bytes_processed
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.estimated_bytes_processed
- fullName: google.cloud.bigquery.job.QueryJob.etag
  isExternal: false
  name: etag
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.etag
- fullName: google.cloud.bigquery.job.QueryJob.exception
  isExternal: false
  name: exception
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.exception
- fullName: google.cloud.bigquery.job.QueryJob.exists
  isExternal: false
  name: exists
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.exists
- fullName: google.cloud.bigquery.job.QueryJob.flatten_results
  isExternal: false
  name: flatten_results
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.flatten_results
- fullName: google.cloud.bigquery.job.QueryJob.from_api_repr
  isExternal: false
  name: from_api_repr
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.from_api_repr
- fullName: google.cloud.bigquery.job.QueryJob.job_id
  isExternal: false
  name: job_id
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.job_id
- fullName: google.cloud.bigquery.job.QueryJob.job_type
  isExternal: false
  name: job_type
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.job_type
- fullName: google.cloud.bigquery.job.QueryJob.labels
  isExternal: false
  name: labels
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.labels
- fullName: google.cloud.bigquery.job.QueryJob.location
  isExternal: false
  name: location
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.location
- fullName: google.cloud.bigquery.job.QueryJob.maximum_billing_tier
  isExternal: false
  name: maximum_billing_tier
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.maximum_billing_tier
- fullName: google.cloud.bigquery.job.QueryJob.maximum_bytes_billed
  isExternal: false
  name: maximum_bytes_billed
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.maximum_bytes_billed
- fullName: google.cloud.bigquery.job.QueryJob.num_child_jobs
  isExternal: false
  name: num_child_jobs
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.num_child_jobs
- fullName: google.cloud.bigquery.job.QueryJob.num_dml_affected_rows
  isExternal: false
  name: num_dml_affected_rows
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.num_dml_affected_rows
- fullName: google.cloud.bigquery.job.QueryJob.parent_job_id
  isExternal: false
  name: parent_job_id
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.parent_job_id
- fullName: google.cloud.bigquery.job.QueryJob.path
  isExternal: false
  name: path
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.path
- fullName: google.cloud.bigquery.job.QueryJob.priority
  isExternal: false
  name: priority
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.priority
- fullName: google.cloud.bigquery.job.QueryJob.project
  isExternal: false
  name: project
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.project
- fullName: google.cloud.bigquery.job.QueryJob.query
  isExternal: false
  name: query
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.query
- fullName: google.cloud.bigquery.job.QueryJob.query_parameters
  isExternal: false
  name: query_parameters
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.query_parameters
- fullName: google.cloud.bigquery.job.QueryJob.query_plan
  isExternal: false
  name: query_plan
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.query_plan
- fullName: google.cloud.bigquery.job.QueryJob.range_partitioning
  isExternal: false
  name: range_partitioning
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.range_partitioning
- fullName: google.cloud.bigquery.job.QueryJob.referenced_tables
  isExternal: false
  name: referenced_tables
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.referenced_tables
- fullName: google.cloud.bigquery.job.QueryJob.reload
  isExternal: false
  name: reload
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.reload
- fullName: google.cloud.bigquery.job.QueryJob.reservation_usage
  isExternal: false
  name: reservation_usage
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.reservation_usage
- fullName: google.cloud.bigquery.job.QueryJob.result
  isExternal: false
  name: result
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.result
- fullName: google.cloud.bigquery.job.QueryJob.running
  isExternal: false
  name: running
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.running
- fullName: google.cloud.bigquery.job.QueryJob.schema
  isExternal: false
  name: schema
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.schema
- fullName: google.cloud.bigquery.job.QueryJob.schema_update_options
  isExternal: false
  name: schema_update_options
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.schema_update_options
- fullName: google.cloud.bigquery.job.QueryJob.script_statistics
  isExternal: false
  name: script_statistics
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.script_statistics
- fullName: google.cloud.bigquery.job.QueryJob.self_link
  isExternal: false
  name: self_link
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.self_link
- fullName: google.cloud.bigquery.job.QueryJob.session_info
  isExternal: false
  name: session_info
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.session_info
- fullName: google.cloud.bigquery.job.QueryJob.set_exception
  isExternal: false
  name: set_exception
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.set_exception
- fullName: google.cloud.bigquery.job.QueryJob.set_result
  isExternal: false
  name: set_result
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.set_result
- fullName: google.cloud.bigquery.job.QueryJob.slot_millis
  isExternal: false
  name: slot_millis
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.slot_millis
- fullName: google.cloud.bigquery.job.QueryJob.started
  isExternal: false
  name: started
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.started
- fullName: google.cloud.bigquery.job.QueryJob.state
  isExternal: false
  name: state
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.state
- fullName: google.cloud.bigquery.job.QueryJob.statement_type
  isExternal: false
  name: statement_type
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.statement_type
- fullName: google.cloud.bigquery.job.QueryJob.table_definitions
  isExternal: false
  name: table_definitions
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.table_definitions
- fullName: google.cloud.bigquery.job.QueryJob.time_partitioning
  isExternal: false
  name: time_partitioning
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.time_partitioning
- fullName: google.cloud.bigquery.job.QueryJob.timeline
  isExternal: false
  name: timeline
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.timeline
- fullName: google.cloud.bigquery.job.QueryJob.to_api_repr
  isExternal: false
  name: to_api_repr
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.to_api_repr
- fullName: google.cloud.bigquery.job.QueryJob.to_arrow
  isExternal: false
  name: to_arrow
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.to_arrow
- fullName: google.cloud.bigquery.job.QueryJob.to_dataframe
  isExternal: false
  name: to_dataframe
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.to_dataframe
- fullName: google.cloud.bigquery.job.QueryJob.to_geodataframe
  isExternal: false
  name: to_geodataframe
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.to_geodataframe
- fullName: google.cloud.bigquery.job.QueryJob.total_bytes_billed
  isExternal: false
  name: total_bytes_billed
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.total_bytes_billed
- fullName: google.cloud.bigquery.job.QueryJob.total_bytes_processed
  isExternal: false
  name: total_bytes_processed
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.total_bytes_processed
- fullName: google.cloud.bigquery.job.QueryJob.transaction_info
  isExternal: false
  name: transaction_info
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.transaction_info
- fullName: google.cloud.bigquery.job.QueryJob.udf_resources
  isExternal: false
  name: udf_resources
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.udf_resources
- fullName: google.cloud.bigquery.job.QueryJob.undeclared_query_parameters
  isExternal: false
  name: undeclared_query_parameters
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.undeclared_query_parameters
- fullName: google.cloud.bigquery.job.QueryJob.use_legacy_sql
  isExternal: false
  name: use_legacy_sql
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.use_legacy_sql
- fullName: google.cloud.bigquery.job.QueryJob.use_query_cache
  isExternal: false
  name: use_query_cache
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.use_query_cache
- fullName: google.cloud.bigquery.job.QueryJob.user_email
  isExternal: false
  name: user_email
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.user_email
- fullName: google.cloud.bigquery.job.QueryJob.write_disposition
  isExternal: false
  name: write_disposition
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.write_disposition
- fullName: google.cloud.bigquery.job.QueryJob.__init__
  isExternal: false
  name: __init__
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.__init__
- fullName: google.cloud.bigquery.job.QueryJob.bi_engine_stats
  isExternal: false
  name: bi_engine_stats
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.bi_engine_stats
- fullName: google.cloud.bigquery.job.QueryJob.dml_stats
  isExternal: false
  name: dml_stats
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob.dml_stats
- fullName: google.cloud.bigquery.job.QueryJob
  isExternal: false
  name: QueryJob
  parent: google.cloud.bigquery.job.QueryJob
  uid: google.cloud.bigquery.job.QueryJob
